{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input widgets\n",
    "pretrained_model_name_or_path = \"/workspace/loras/anylora-v1.safetensors\"\n",
    "train_data_dir = \"/workspace/loras/TestmanLora/img\"\n",
    "output_dir = \"/workspace/loras/TestmanLora/model\"\n",
    "output_name = \"Testman-v1-8\"\n",
    "save_model_as = \"safetensors\"\n",
    "network_module = \"networks.lora\"\n",
    "noise_offset = 0.1\n",
    "optimizer_type = \"Lion\"\n",
    "max_train_steps = 5\n",
    "save_every_n_epochs = 1\n",
    "max_train_epochs = 1\n",
    "network_alpha = 128\n",
    "unet_lr = 0.0001\n",
    "network_dim = 128\n",
    "resolution = \"512,512\"\n",
    "bucket_reso_steps = 64\n",
    "text_encoder_lr = 5e-5\n",
    "clip_skip = 2\n",
    "mem_eff_attn = True\n",
    "enable_bucket = True\n",
    "gradient_checkpointing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_train_network_command(pretrained_model_name_or_path, train_data_dir, output_dir, output_name, save_model_as,\n",
    "                              network_module, noise_offset, optimizer_type, max_train_steps, save_every_n_epochs,\n",
    "                              max_train_epochs, network_alpha, unet_lr, network_dim, resolution, bucket_reso_steps,\n",
    "                              text_encoder_lr, clip_skip, mem_eff_attn, enable_bucket, gradient_checkpointing):\n",
    "    \n",
    "    print(\"Training network...\")\n",
    "\n",
    "    print(f\"Pretrained Model: {pretrained_model_name_or_path}\")\n",
    "    print(f\"Train Data Directory: {train_data_dir}\")\n",
    "    print(f\"Output Directory: {output_dir}\")\n",
    "    print(f\"Output Name: {output_name}\")\n",
    "    print(f\"Save Model As: {save_model_as}\")\n",
    "    print(f\"Network Module: {network_module}\")\n",
    "    print(f\"Noise Offset: {noise_offset}\")\n",
    "    print(f\"Optimizer Type: {optimizer_type}\")\n",
    "    print(f\"Max Train Steps: {max_train_steps}\")\n",
    "    print(f\"Save Every n Epochs: {save_every_n_epochs}\")\n",
    "    print(f\"Max Train Epochs: {max_train_epochs}\")\n",
    "    print(f\"Network Alpha: {network_alpha}\")\n",
    "    print(f\"UNET Learning Rate: {unet_lr}\")\n",
    "    print(f\"Network Dimension: {network_dim}\")\n",
    "    print(f\"Resolution: {resolution}\")\n",
    "    print(f\"Bucket Resolution Steps: {bucket_reso_steps}\")\n",
    "    print(f\"Text Encoder Learning Rate: {text_encoder_lr}\")\n",
    "    print(f\"Clip Skip: {clip_skip}\")\n",
    "    print(f\"Memory-efficient Attention: {mem_eff_attn}\")\n",
    "    print(f\"Enable Bucket: {enable_bucket}\")\n",
    "    print(f\"Gradient Checkpointing: {gradient_checkpointing}\")\n",
    "\n",
    "    # Construct the command\n",
    "    command = f\"python ./train_network.py \\\n",
    "        --pretrained_model_name_or_path=\\\"{pretrained_model_name_or_path}\\\" \\\n",
    "        --train_data_dir=\\\"{train_data_dir}\\\" \\\n",
    "        --output_dir=\\\"{output_dir}\\\" \\\n",
    "        --output_name=\\\"{output_name}\\\" \\\n",
    "        --save_model_as={save_model_as} \\\n",
    "        --network_module={network_module} \\\n",
    "        --noise_offset={noise_offset} --optimizer_type={optimizer_type} \\\n",
    "        --max_train_steps=\\\"{max_train_steps}\\\" \\\n",
    "        --save_every_n_epochs=\\\"{save_every_n_epochs}\\\" \\\n",
    "        --max_train_epochs=\\\"{max_train_epochs}\\\" \\\n",
    "        --network_alpha=\\\"{network_alpha}\\\" \\\n",
    "        --unet_lr={unet_lr} \\\n",
    "        --network_dim={network_dim} \\\n",
    "        --resolution={resolution} \\\n",
    "        --bucket_reso_steps={bucket_reso_steps} \\\n",
    "        --text_encoder_lr={text_encoder_lr} \\\n",
    "        --unet_lr={unet_lr} \\\n",
    "        --network_dim={network_dim} \\\n",
    "        --clip_skip={clip_skip}\"\n",
    "\n",
    "    if mem_eff_attn:\n",
    "        command += \" --mem_eff_attn\"\n",
    "    if enable_bucket:\n",
    "        command += \" --enable_bucket\"\n",
    "    if gradient_checkpointing:\n",
    "        command += \" --gradient_checkpointing\"\n",
    "\n",
    "    # Run the command\n",
    "    subprocess.run(command, shell=True)\n",
    "\n",
    "\n",
    "run_train_network_command(\n",
    "    pretrained_model_name_or_path=pretrained_model_name_or_path,\n",
    "    train_data_dir=train_data_dir,\n",
    "    output_dir=output_dir,\n",
    "    output_name=output_name,\n",
    "    save_model_as=save_model_as,\n",
    "    network_module=network_module,\n",
    "    noise_offset=noise_offset,\n",
    "    optimizer_type=optimizer_type,\n",
    "    max_train_steps=max_train_steps,\n",
    "    save_every_n_epochs=save_every_n_epochs,\n",
    "    max_train_epochs=max_train_epochs,\n",
    "    network_alpha=network_alpha,\n",
    "    unet_lr=unet_lr,\n",
    "    network_dim=network_dim,\n",
    "    resolution=resolution,\n",
    "    bucket_reso_steps=bucket_reso_steps,\n",
    "    text_encoder_lr=text_encoder_lr,\n",
    "    clip_skip=clip_skip,\n",
    "    mem_eff_attn=mem_eff_attn,\n",
    "    enable_bucket=enable_bucket,\n",
    "    gradient_checkpointing=gradient_checkpointing\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
